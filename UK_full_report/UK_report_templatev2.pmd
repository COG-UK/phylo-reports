
# UK lineages summary report

```python, echo=False, name='define_paths'
import os

#default is current working directory
#this will come in here and also in the pweave call
output_directory ="" ##CHANGE

input_directory = "" ##CHANGE

metadata_file = "" ##CHANGE

name_stem="" ##CHANGE

week = "" ##CHANGE

fd = os.path.join(output_directory, "figures_" + week)

scripts_directory = "" ##CHANGE

adm2_cleaning_file = "%s/utils/mapping_files/adm2_cleaning.csv" % scripts_directory

```

```python, echo=False,name='import_dependencies'
import matplotlib.pyplot as plt
from collections import defaultdict
from collections import Counter
import pandas as pd
import os
from tabulate import tabulate
import imp
import warnings
warnings.filterwarnings("ignore")

import matplotlib as mpl
import matplotlib.font_manager as font_manager

font_list = font_manager.fontManager.addfont("%s/utils/helveticaneue/HelveticaNeue.ttf" % scripts_directory)
#font_list = font_manager.fontManager.addfont("%s/utils/helveticaneue/HelveticaNeueBD.ttf" % scripts_directory)

mpl.rcParams['font.family'] = 'helveticaneue'
mpl.rcParams['font.weight']=1000
mpl.rcParams['axes.labelweight']=300
mpl.rcParams['font.size']=20

plt.rcParams.update({'figure.max_open_warning': 0})

import UK_full_report.utils.basic_descriptions as descrip
import UK_full_report.utils.make_uk_introduction_trees as tree_func
import UK_full_report.utils.descriptive_plots as dp
import UK_full_report.utils.case_definitions as case_defs
import UK_full_report.utils.time_functions as time
import UK_full_report.utils.data_parsing as parse
import UK_full_report.utils.lineage_exploration as lin_exp
import UK_full_report.utils.writing_summary_files as writing
import UK_full_report.utils.mapping as map

```
```python, name='prepping things and prelim info',echo=False, results='tex'

current_date = time.make_current_week(week)

intro_bigs, intro_smalls, intro_alls, count, intro_countries, intro_object_dict, omitted, taxa, new_lineages, taxon_dictionary, most_recent_sample, intro_int_list, unclear_taxa = parse.make_objects(metadata_file)
singletons_count, smalls_count = descrip.get_preliminary_info(intro_countries)

print("This report gives summaries of UK specific lineages for week " + week + ". ")
print("There are time lags due to batching, curation and analysis, the most recently sampled sequence is " + str(most_recent_sample) + ". The analysis (eg time since last sample) is therefore undertaken from this date.")

print("<br/>")
print(str(count) + " sequences in the UK have been included in this analysis.")
print(str(len(intro_countries)) + " lineages have been recorded, " + str(singletons_count) + " of which only contain one sequence.")

```
Note: the size of a lineage may be due to a low amount of transmission of this lineage, but it is likely also that it just hasn't been sampled as frequently, especially for newer lineages.

Sequences which were replicates or too error-prone were removed from this analysis.

```python, echo=False, results='tex'
print(str(smalls_count) + " are lineages which only contained five sequences or fewer, and so have been left out of visualisation in the interests of clarity")
```
```python, echo=False, name='status description', results='tex'

#split = lin_exp.find_splits(intro_alls)

status_counts, reactivated_lineages, continuining_lineages = lin_exp.describe_lineages(intro_bigs)

reactivateds = status_counts["Reactivated"]
actives = status_counts["Reactivated"] + status_counts["Continuing"]
continuous = status_counts["Continuing"]
pendings = status_counts["Pending extinction"]
extincts = status_counts["Extinct"]
quiets = status_counts["Gone quiet"]


print("Of the " + str(len(intro_alls) - len(intro_smalls)) + " that remain:")

if pendings > 0:
    if pendings == 1:
        print(str(pendings) + "is pending extinction ie last seen three weeks ago.")
    else:
        print(str(pendings) + " are pending extinction, ie last seen three weeks ago.")


if extincts > 0:
    if extincts == 1:
        print(str(extincts) + " has not been seen for more than one month, and so is viewed as extinct, but will continue to be monitored.")
    else:
        print(str(extincts) + " have not been seen for more than one month, and so are viewed as extinct, but will continue to be monitored.")

if quiets>0:
    if quiets == 1:
        print(str(quiets) + " has gone quiet, ie haven't been seen this week.")
    else:
        print(str(quiets) + " lineages have gone quiet, ie haven't been seen this week.")

if reactivateds > 0:
    if reactivateds == 1:
        print(str(reactivateds) + " has reactivated.")
    else:
        print(str(reactivateds) + " lineages have reactivated.")

if continuous > 0:
    
    if continuous == 1:
        print(str(continuous) + " lineage has been continuously circulating.")
    else:
        print(str(continuous) + " lineages have been continuously circulating.")

#if len(split) != 0:
 #   print(str(len(split)) + " lineages have split since last week. They are removed from further inspection until they have been manually curated.")
  #  if len(split) <= 10:
   #     print("The split lineages are: ")
    #    for i in split:
     #       print(i.id)
    #else:
     #   print("There are more than ten split lineages, so please see the summary files for more information.")
    
    #for this week this is ok
    #for lin in split:
     #   intro_alls.remove(lin)
      #  if lin in intro_bigs:
       #     intro_bigs.remove(lin)

```

The following table contains information about lineages and the number of sequences in each country in the UK for each lineage, in reverse size order. 
Each entry is the count of sequences from each lineage in each country, with the percentage of the total sequences from that lineage that this count represents.

It is also written to "summary_files" as "lineage_summary.tsv" for further use. 
```python, name="dataframe fun", echo=False, results='tex'
intro_country_counts, intro_country_percentages, intro_country_together, intro_total_numbers = descrip.prep_dicts(intro_countries)
dataframe, tree_order = descrip.make_dataframe(intro_country_together, intro_total_numbers, intro_object_dict)

print(dataframe.to_markdown())
```

```python,name="producing summary files", echo=False

writing.write_summary_files(output_directory, dataframe, omitted, week, intro_alls)

```

These data is represented in the stacked bar chart below. Note that the number of sequences is likely to be due more to differing sampling efforts in different regions, rather than genuine differences in numbers of cases. 

The raw data for this bar chart are in the table above. 

```python, name="stacked_bars_by_country", echo=False, include=False

df_counts, df_thinned, df_acctrans_counts = dp.make_plotting_dfs(intro_country_counts, intro_object_dict)

dp.plot_bars(intro_bigs)

```

```python, name="hack_figure", echo=False, results='raw'
print("![](" + fd + "/" + name_stem + "_stacked_bars_by_country_1.png)\\")
```

The relative growth and decline of the ten most sampled lineages in terms of number of counties they are present in is shown below. 
The raw data for the plot is shown below it, with each column representing a lineage, and the number of admin2 regions it is present in in each week.


```python,name="geog_plot", echo=False, include=False
y_dict, week_list = dp.plot_geog_plot(intro_bigs, False)
raw_geog = dp.make_raw_data_geog_plot(y_dict, week_list)
```
```python,name="hack",echo=False,results='raw'
print("![](" + fd + "/" + name_stem + "_geog_plot_1.png)\\")
print(raw_geog.to_markdown())
```

The date of first sequence in the cluster is shown below for every cluster with date information. 

```python,name="firsts_plot", echo=False, include=False
multi, single = dp.plot_starts(intro_alls)
starts_raw = dp.raw_data_starts(single, multi)
```
```python,name="hack",echo=False,results='raw'
print("![](" + fd + "/" + name_stem + "_firsts_plot_1.png)\\")
print(starts_raw.to_markdown())
```
For comparison, here is a plot of the day that every sequence was taken, coloured by country. Note that sequences without dates were not included.

```python, name="seqs_over_time", echo=False, include=False
days, E, S, W, NI = dp.plot_sequences_over_time(taxa)
raw_seqs_over_time = dp.raw_data_seqs_over_time(days, E, S, W, NI)
```
```python, name="hack", echo=False, results='raw'
print("![](" + fd + "/" + name_stem + "_seqs_over_time_1.png)\\")
print(raw_seqs_over_time.to_markdown())
```

These lineages are shown on the timeline below. Each line represents the length of the cluster, from oldest to most recent sampling date.
The dots are sized by the number of sequences taken on that date, and again are colour coded by country.


```python, name="make_timeline", echo=False, results='tex', include=False
dp.make_timeline(intro_bigs)
timeline_df = dp.raw_data_timeline(intro_bigs)
print(timeline_df.to_markdown)
timeline_df.to_csv(output_directory + "timeline_raw_data.csv", index=False)
```

```python, name="hack2", echo=False, results='raw'
print("![](" + fd + "/" + name_stem + "_make_timeline_1.png)\\")
```

The map below shows the number of sequences sampled in each admin2 region in the UK. The colour scale is the same for all four countries, but with different underlying base colours.

```python, name="map", include=False, results='tex', echo=False

uk_json = "%s/utils/mapping_files/gadm36_GBR_2.json" % scripts_directory
channels = "%s/utils/mapping_files/channel_islands.json" % scripts_directory
NI_json = "%s/utils/mapping_files/NI_counties.geojson" % scripts_directory

input_geojsons = [uk_json, channels, NI_json]

new_uncleans = map.make_map(input_geojsons, adm2_cleaning_file, metadata_file, output_directory, week)
```
```python, name="hack3", echo=False, results='raw'
#RAW data - just the dataframe cols of merged_locs and number of seqs
print("![](" + fd + "/" + name_stem + "_map_1.png)\\")
```


```python, name="uncleans", echo=False, results='tex'
if new_uncleans:
    print("There are some sequences with locations that are not matched to real Admin2 regions, some manual curation required.")
```




Other results modules for UK lineage analysis can be added in here if required.

\pagebreak

## Appendix

The plot below shows the number of sequences from each country that don't have specific enough location data to plot on the map. 
```python, name="hack4", echo=False, results='raw'
print("![](" + fd + "/" + name_stem + "_map_2.png)\\")
```

```python, echo=False, fig=False, name="trees", include=True 
if input_directory != "":
    print("Trees and associated pie charts have been made and put into the figures folder")
    intro_list = tree_func.make_all_of_the_trees(input_directory, df_acctrans_counts, tree_order, intro_object_dict, taxon_dictionary)
```
